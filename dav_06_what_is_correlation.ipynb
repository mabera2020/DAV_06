{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='maroon'>What is Correlation?</font>\n",
    "\n",
    "This notebook touches on:\n",
    "* Correlation\n",
    "* Quick Visualizations\n",
    "* Unusual Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we learn how to measure correlations between quantities. For example, in an economy, as inflation goes up, the price of oil also goes up. This is an example of a linear relationship that can be quantified by calculating the correlation coefficient between inflation and oil.  \n",
    "\n",
    "<p></p>\n",
    "In this notebook, we'll look at how to calculate the Pearson correlation coefficient, which measures the strength of a linear relationship between two continuous variables. We will be using a dataset on Weight and Metabolic rates of 44 women to help us learn how to apply this measure. \n",
    "\n",
    "<p></p>\n",
    "In Python, the Scipy library provides a function called `pearsonr()` to calculate  the strength of a linear relationship.\n",
    "We start to use the [Scipy](https://scipy.org/scipylib/index.html) statistics library for our analysis. Scipy is a powerful statistics library that works with Numpy, Matplotlib, and Pandas. So you can easily use functions for statistical analysis on dataframes or Numpy arrays. There are other statistics Python modules like Statsmodels and Scikits. Statsmodels has the same functions as and uses Scipy.stats; and Scikits is optimized for machine learning. Statsmodels also works with Pandas dataframes.\n",
    "<p></p>\n",
    "No one library is perfect, you might need to put together different libraries to do what you want. We choose Scipy as a starting step. We use scipy.stats because it provides user-friendly functions for statistical tests. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we measure correlation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A measure of correlation determines how one variable increases or decreases as another increases or decreases. We'll use a widely used measure called the Pearson correlation measure to determine the strength of a linear relationship between two quantities or continuous variables. Suppose we want to know if there is a relationship between the weight (in kilograms) and metabolic rates (calories/day) of 44 women. How do you use the Pearson correlation measure to quantify this relationship?\n",
    "\n",
    "The Pearson measure returns a coefficient $r$ that lies between -1 and +1. To determine the strength of a linear relationship between variables $x$ and $y$, we use the following formula:\n",
    "\n",
    "$$r_{x,y} = \\dfrac{\\sum(x_i - \\overline{x})(y_i - \\overline{y})}{\\sqrt{\\sum(x_i - \\overline{x})^2\\sum(y_i - \\overline{y})^2}},$$ where $x_i$ is a single observation, $\\overline{x}$ the mean of the set of $x$ data points, $y_i$ is a single observation, and $\\overline{y}$ the mean of the set of $y$ data points. The formula subtracts observations from their means and rescales them by a measure of their standard deviations. By rescaling, the result falls in the range $$-1 \\leq r \\leq 1.$$\n",
    "\n",
    "<img src='images/blog-introduction-to-correlation-learn-data-science-tutorials-img-1.png'/>\n",
    "Image courtesy of [Introduction to correlation](https://www.datascience.com/blog/introduction-to-correlation-learn-data-science-tutorials).\n",
    "\n",
    "\n",
    "A correlation coefficient close to<b> +1</b> indicates a <b>strong positive relationship</b>.\n",
    "\n",
    "A correlation coefficeint close to<b> -1</b> indicates a<b> strong negative relationship</b>.\n",
    "\n",
    "A correlation coefficient equal to <b>zero</b> indicates <b>no relationship exists between the variables</b>.\n",
    "\n",
    "There are other correlation measures, like Spearman rank correlation calculates a measure based on ranked data. Spearman rank correlation is also not restricted to linear relationships between variables. We will focus on Spearman rank correlation in later sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset\n",
    "\n",
    "First, let's begin by importing the necessary libraries for finding correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np              # import the necessary libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats      # import scipy.stats and rename it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the dataset into a Pandas frame and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('weight-and-metabolic.csv', sep=',')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's study the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are indeed 44 observations, with two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And generate summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand a bit more about the data, let's proceed to visualizations.\n",
    "\n",
    "A scatterplot is a great way to visualize a relationship between the continous variables of interest. Let's use a Seaborn function to create a scatterplot. Remember, Seaborn is great for statistically-minded plots which would otherwise require more coding with Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lmplot('Body weight',   # x-axis\n",
    "               'Metabolic rate',# y-axis\n",
    "               data=data,       # dataframe\n",
    "               fit_reg=True)   # fit regression line\n",
    "\n",
    "g.fig.set_size_inches(10,10)    # set the size of the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The function `lmplot()` stands for linear model plot. It produces a scatterplot and fits a regression model. \n",
    "\n",
    "The regression line is optimal, as it minimizes the distance of all points to itself. Because of this property, the slope of the regression line of Y and X is mathematically equivalent to correlation between X and Y, standardized by the ratio of their standard deviations:\n",
    "\n",
    "$$\\rho = b\\frac{s_x}{s_y}$$\n",
    "\n",
    "where b is the slope of the regression line of Y from X.\n",
    "\n",
    "In other words, correlation reflects the association and amount of variability between the two variables.\n",
    "\n",
    "This relationship with the slope of the line has two important implications:\n",
    "\n",
    "    1) It makes it more clear why Pearson correlation describes linear relationships\n",
    "    2) It also shows why correlation is important and so widely used in predictive modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line of best fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line of best fit is a straight line drawn through a set of datapoints in a scatterplot to give the best approximation of the data. We won't go into how this line is generated (e.g. least squares method). However, the Pearson correlation coefficient is a measure of how far away the datapoints for two variables are from this line.\n",
    "\n",
    "A correlation coefficient of +1 or -1 does not only represents positive or negative correlation respectively. These values indicate that all the datapoints for the two variables follow this line of best fit. As r -> 0, the variation of the data points around the line of best fit increases and is interpreted as a reduced/no linear relationship between the variables.\n",
    "\n",
    "With Scipy.stats, we can calculate r as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r- Pearson correlation coefficient\n",
    "# p - probability of observing a correlation that extreme in the dataset\n",
    "r, p = stats.pearsonr(data['Body weight'], data['Metabolic rate'])\n",
    "print(r)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Body weight and Metabolic rate for the 44 women are highly positively correlated. Assuming an alpha level of 5%, the p-value we see above indicates that indeed there is a relationship between the two variables: Body Weight and Metabolic rate. (Null hypothesis is that there is no relationship between the two - without regard to the strength of the relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unusual values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from showing the association between two variables, scatterplots can indicate whether there are outliers or influential values that could affect the strength of the relationship between variables in a dataset. Look back at the figure we quickly generated above. Do you notice any outliers? If you look closely, you will notice that one of the points exceeds a metabolic rate of 2000. The same thing can be confirmed using other visual tools like we looked at before such as histograms and boxplots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying outliers with boxplots and histograms\n",
    "\n",
    "To identify outliers, we can use a box plot. We see two outliers for both the `Body weight` and `Metabolic rate`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a boxplot of the Body weight\n",
    "sns.boxplot(data['Body weight'], orient='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot a boxplot of the Metabolic rate\n",
    "sns.boxplot(data=data['Metabolic rate'], orient='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both variables, we see an outlier to the right of the box, beyond the upper limit whisker of the plot. This indicates that the data is skewed to the right and the mean is higher than the median. Take a look at how the data looks when plotted on a histogram. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Pracitce Challenge</b>: Produce histograms for the `Body weight` and `Metabolic rate` columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your answer\n",
    "#first find the right function in Seaborn to plot histograms then\n",
    "#plot histogram for Birthweight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot histogram for Metabolic Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the shape of your histograms compare to the boxplots and the scatterplot, especially with regard to the presence of outliers? Enter your discussion in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>#Discuss shape of histograms here#</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, why do we look into outliers? It turns out that Pearson correlation testing is sensitive to outliers. If an outlier has high influence on the correlation analysis, it could result in a false correlation coefficient, slope of the regression line, predicted results or hypothesis test results, if any. It's important to verify whether these unusual datapoints make a difference for your analysis and application of the results.\n",
    "\n",
    "<b> Outliers</b> are points that don't fit the general trend of the regression line and are normally extreme in the y-direction.\n",
    "<b> Leverage points </b> are another type of unusual observation and are usually extreme in the x-direction. In the scatterplot, we saw an outlier exceeding metabolic rate 2000. In the exercise below, you will evaluate whether this outlier affects the correlation results we previously found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Determine whether the observed data point influences your correlation results. Locate and remove the datapoint, re-plot the histogram and recalculate the correlation coefficient to see if there is a difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Locate and remove the unusual datapoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Re-plot the scatterplot to ensure no more outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Recalculate the correlation coefficient and compare your results to the previous output when the outlier was included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "For another explanation on correlation see [Introduction to Correlation](https://www.datascience.com/blog/introduction-to-correlation-learn-data-science-tutorials).\n",
    "\n",
    "For more on unusual values: outliers and leverage points see [Unusual Observations](http://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/supporting-topics/model-assumptions/unusual-observations/).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
